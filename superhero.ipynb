{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "superhero",
      "provenance": [],
      "authorship_tag": "ABX9TyP2AtH1m8dMa2FwozvRhJmv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaQtiml/Kaggle_Practice/blob/main/superhero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTZX8USgE_iV",
        "outputId": "c8d5d1eb-0aa7-45a4-8d37-4b558e3ec004"
      },
      "source": [
        "!git clone https://github.com/am1tyadav/superhero"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'superhero'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80nNWiEVG4Ds"
      },
      "source": [
        "with open(\"superhero/superheroes.txt\") as f:\n",
        "    data = f.read()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A1NhuUASHDu_",
        "outputId": "477beec1-8ca7-46e5-c409-e9c894ffa9bb"
      },
      "source": [
        "data[:100]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jumpa\\t\\ndoctor fate\\t\\nstarlight\\t\\nisildur\\t\\nlasher\\t\\nvarvara\\t\\nthe target\\t\\naxel\\t\\nbattra\\t\\nchangeling\\t\\npyrrh'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po8BH4DRGX-4"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r8eX2dDFWc1"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~',\n",
        "    split='\\n',\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30wgwd-PGnBp"
      },
      "source": [
        "tokenizer.fit_on_texts(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6aRqg_OGy8H"
      },
      "source": [
        "char_to_index = tokenizer.word_index\n",
        "index_to_char = dict((v,k) for k,v in char_to_index.items())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj-IqyV4Hi9A",
        "outputId": "247cb0e9-5d27-48a5-c277-36237a843b8c"
      },
      "source": [
        "print(char_to_index)\n",
        "print(index_to_char)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\t': 1, 'a': 2, 'e': 3, 'r': 4, 'o': 5, 'n': 6, 'i': 7, ' ': 8, 't': 9, 's': 10, 'l': 11, 'm': 12, 'h': 13, 'd': 14, 'c': 15, 'u': 16, 'g': 17, 'k': 18, 'b': 19, 'p': 20, 'y': 21, 'w': 22, 'f': 23, 'v': 24, 'j': 25, 'z': 26, 'x': 27, 'q': 28}\n",
            "{1: '\\t', 2: 'a', 3: 'e', 4: 'r', 5: 'o', 6: 'n', 7: 'i', 8: ' ', 9: 't', 10: 's', 11: 'l', 12: 'm', 13: 'h', 14: 'd', 15: 'c', 16: 'u', 17: 'g', 18: 'k', 19: 'b', 20: 'p', 21: 'y', 22: 'w', 23: 'f', 24: 'v', 25: 'j', 26: 'z', 27: 'x', 28: 'q'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUSBbrlZIj-Y"
      },
      "source": [
        "# Names and Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww4SLbaJHlZv",
        "outputId": "269ff1a3-0ccb-4111-d8dc-936165e5c435"
      },
      "source": [
        "names = data.splitlines()\n",
        "names[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jumpa\\t',\n",
              " 'doctor fate\\t',\n",
              " 'starlight\\t',\n",
              " 'isildur\\t',\n",
              " 'lasher\\t',\n",
              " 'varvara\\t',\n",
              " 'the target\\t',\n",
              " 'axel\\t',\n",
              " 'battra\\t',\n",
              " 'changeling\\t']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vooYhaz-H9a0",
        "outputId": "a9be2715-b460-40c8-9e65-72f576de02e1"
      },
      "source": [
        "tokenizer.texts_to_sequences(names[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25], [16], [12], [20], [2], [1]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q5KwtfQIBrV"
      },
      "source": [
        "def name_to_seq(name):\n",
        "    return [tokenizer.texts_to_sequences(chr)[0][0] for chr in name]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNJMS48AIVC2",
        "outputId": "e28b8662-5394-45bd-c9e4-ac057c119209"
      },
      "source": [
        "name_to_seq(names[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 16, 12, 20, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDTDnLhaIdMu"
      },
      "source": [
        "def seq_to_name(seq):\n",
        "    return \"\".join([index_to_char[num] for num in seq if num!=0])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wusw9gb6JIRm",
        "outputId": "84f4b2f2-e920-4128-f173-ce73c887ffc7"
      },
      "source": [
        "seq_to_name(name_to_seq(names[0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jumpa\\t'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNaiTIq2JNb4"
      },
      "source": [
        "# Creating Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xy5yboJgJ2"
      },
      "source": [
        "sequences = []\n",
        "for name in names:\n",
        "    seq = name_to_seq(name)\n",
        "    if(len(seq)>=2):\n",
        "        sequences += [seq[:i] for i in range(2,len(seq)+1)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQjIz09jKQHn",
        "outputId": "700ae57a-5c93-4522-8524-6f96ebefb3da"
      },
      "source": [
        "print(names[0])\n",
        "print(name_to_seq(names[0]))\n",
        "print(sequences[:4])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumpa\t\n",
            "[25, 16, 12, 20, 2, 1]\n",
            "[[25, 16], [25, 16, 12], [25, 16, 12, 20], [25, 16, 12, 20, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GadFSkBYKSFf"
      },
      "source": [
        "max_len = max([len(x) for x in sequences])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esRp-93iKz_n",
        "outputId": "8a7a7c25-f82f-4318-e44e-13ac26b98cc8"
      },
      "source": [
        "print(max_len)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DbjL7r4K1We"
      },
      "source": [
        "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences,\n",
        "    padding = \"pre\",\n",
        "    maxlen = max_len\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU5NubRaLN-X",
        "outputId": "9c53d544-78cc-4575-9757-c98fadabbfcf"
      },
      "source": [
        "print(padded_sequences[1])\n",
        "print(padded_sequences.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0 25 16 12]\n",
            "(88279, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-XfZBnALReX"
      },
      "source": [
        "# Training and Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vha2Vz_wLsdw"
      },
      "source": [
        "# Training Set\n",
        "x = padded_sequences[:,:-1] # save the last character to check with the predicted one.\n",
        "y = padded_sequences[:,-1]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLhfTaPtMbFf",
        "outputId": "5dc7a64d-8941-4437-b0a1-29eee54b7b37"
      },
      "source": [
        "print(x.shape,y.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(88279, 32) (88279,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_45n2S8gMc7g"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eYSKJuNMt2p",
        "outputId": "c66129c3-f71d-4038-918b-84c2cf9659b9"
      },
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66209, 32) (66209,)\n",
            "(22070, 32) (22070,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK_EwCnvMxi_",
        "outputId": "fa9bad8f-62b8-4299-b80b-d02737bff807"
      },
      "source": [
        "num_chars = len(char_to_index.keys())+1 # +1 is from zero-padding\n",
        "print(num_chars)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdXu5UrENQZv"
      },
      "source": [
        "# Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jskuLt_9Nlwo"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPool1D, LSTM\n",
        "from tensorflow.keras.layers import Bidirectional, Dense"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSmGywrdN-KA",
        "outputId": "d5c9155a-626c-48e2-bbb2-324201ea6171"
      },
      "source": [
        "model = Sequential([\n",
        "                    Embedding(num_chars, 8, input_length = max_len-1),\n",
        "                    Conv1D(64,5, strides = 1, activation = \"tanh\", padding = \"causal\"),\n",
        "                    MaxPool1D(2),\n",
        "                    LSTM(32),\n",
        "                    Dense(num_chars, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# causal means that the output will depend on only the previous data."
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 32, 8)             232       \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 32, 64)            2624      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 29)                957       \n",
            "=================================================================\n",
            "Total params: 16,229\n",
            "Trainable params: 16,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbwiSzMgPjJP"
      },
      "source": [
        "h = model.fit(\n",
        "    x_train ,y_train,\n",
        "    validation_data = (x_test,y_test),\n",
        "    epochs = 50,\n",
        "    verbose = 2,\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", patience = 3)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m2X8ouuSlcK"
      },
      "source": [
        "# Generate Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwEi1nXXVHZ7",
        "outputId": "2b189470-a852-4a3a-ec71-1cd260d133df"
      },
      "source": [
        "seq = name_to_seq(\"M\")\n",
        "padded = tf.keras.preprocessing.sequence.pad_sequences([seq], \n",
        "                                                       padding = \"pre\",\n",
        "                                                       maxlen = max_len-1, \n",
        "                                                       truncating = \"pre\")\n",
        "pred = model.predict(padded)[0]\n",
        "print(tf.argmax(pred).numpy())\n",
        "pred_char = index_to_char[tf.argmax(pred).numpy()]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7KXUdtTS5Sw"
      },
      "source": [
        "def generate_names(seed):\n",
        "    for i in range(40):\n",
        "        seq = name_to_seq(seed)\n",
        "        padded = tf.keras.preprocessing.sequence.pad_sequences([seq], padding = \"pre\", \n",
        "                                                               maxlen = max_len-1, truncating = \"pre\") # -1 as we want to predict the last character\n",
        "        pred = model.predict(padded)[0]\n",
        "        pred_char = index_to_char[tf.argmax(pred).numpy()]\n",
        "        seed += pred_char\n",
        "\n",
        "        if pred_char == \"\\t\":\n",
        "            break\n",
        "    print(seed)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqZdveVKUgSB",
        "outputId": "fe48aabf-1d58-45e1-9748-328467224ecf"
      },
      "source": [
        "generate_names(\"f\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "freeker\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuX9bTxLUkiA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}